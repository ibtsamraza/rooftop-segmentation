from torch.utils.data import Dataset, DataLoader
from transformers import AdamW
import torch
from torch import nn
from sklearn.metrics import accuracy_score
from tqdm import tqdm
import os
from PIL import Image
from transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor,SegformerImageProcessor
import pandas as pd
import cv2
import numpy as np
import albumentations as aug
import matplotlib.pyplot as plt

columns = ['background', 'empty_roof', 'obstacle_on_roof', 'shadw_on_roof', 'solar_pannel']
iou_score = pd.DataFrame(columns=columns)
dice_coeff = pd.DataFrame(columns=columns)
pixel_accuracy = []
y_true = []
y_pred = []

#Function to read and load test images 
def get_file_paths(directory_path):
    # Initialize an empty list to store file paths
    file_paths = []

    # List all files and directories in the given directory
    for entry in os.listdir(directory_path):
        # Create the full path
        full_path = os.path.join(directory_path, entry)

        # Check if the entry is a file and add it to the list
        if os.path.isfile(full_path):
            file_paths.append(full_path)

    return file_paths

#calculate dice coefficient
def dice_coefficient(pred_mask, true_mask, num_classes, smooth=1e-5):
    dice = pd.DataFrame(columns=columns) 
    for class_idx in range(num_classes):
        #get mask and pred for every class
        pred_mask_class = (pred_mask == class_idx).astype(np.uint8)
        true_mask_class = (true_mask == class_idx).astype(np.uint8)

        #find intersection 
        intersection = np.sum(pred_mask_class * true_mask_class)
        total_pixels = np.sum(pred_mask_class) + np.sum(true_mask_class)
        #find dice coefficient
        dice_val = (2.0 * intersection + smooth) / (total_pixels + smooth)
        dice.at[0, columns[class_idx]] = dice_val
    return dice

#Calculate iou for every class
def calculate_iou(pred_mask, true_mask, num_classes, ignore_index=255):
    iou_classwise= pd.DataFrame(columns=columns)    
    for class_label in range(num_classes):
        # Flatten the tensors to simplify calculation
        predicted_flat = (pred_mask == class_label).flatten()
        target_flat = (true_mask == class_label).flatten()
        
        # Ignore specified index
        valid_mask = target_flat != ignore_index
        #print(predicted_flat[valid_mask])

        # Calculate intersection and union
        intersection = np.logical_and(predicted_flat, target_flat).sum()
        union = np.logical_or(predicted_flat, target_flat).sum()

        # Calculate IoU for the current class
        iou_val = intersection / union if union != 0 else 0
        
        iou_classwise.at[0, columns[class_label]] = iou_val

    # Return the average IoU across all classes
    return iou_classwise

#calculate pixelwise accuracy
def pixel_wise_accuracy(pred_mask, true_mask):
    correct_pixels = np.sum(pred_mask == true_mask)
    total_pixels = pred_mask.size
    accuracy = correct_pixels / total_pixels
    return accuracy


# change directory path ot which have your test images
directory_path_image = 'TestData/images'
directory_path_mask = 'TestData/masks'

#call get_file_path function to get the path of images and masks
file_image_list = get_file_paths(directory_path_image)
file_mask_list = get_file_paths(directory_path_mask)

#sort above images and mask lists
file_image_list.sort()
file_mask_list.sort()

#give trained model path her eot load model for inference
roof_model = torch.load('segformer_rooftop_detection_final_model', map_location=torch.device('cpu'))

#check if cuda is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# prepare the image for the model (aligned resize)
feature_extractor_inference = SegformerImageProcessor(align=False, reduce_zero_label=False)

# load a csv file which have color pallete for different classes
df = pd.read_csv('class_dict_seg_1.csv')
classes = df['name']
palette = df[[' r', ' g', ' b']].values
id2label = classes.to_dict()
label2id = {v: k for k, v in id2label.items()}

#loop through our images and mask and find metrices and visualize our predictions 
for x in range(len(file_image_list)):
    #read image
    image  = cv2.imread(file_image_list[x])

    #read mask
    mask = Image.open(file_mask_list[x])
    #convert mask to numpy array
    mask = np.array(mask)

    # prepare the image for the model (aligned resize)
    pixel_values = feature_extractor_inference(image, return_tensors="pt").pixel_values.to(device)
    #call our loaded model
    outputs = roof_model(pixel_values=pixel_values)
    logits = outputs.logits.cpu()

    upsampled_logits = nn.functional.interpolate(logits,
                size=image.shape[:-1], # (height, width)
                mode='bilinear',
                align_corners=False)

    seg = upsampled_logits.argmax(dim=1)[0]
    #seg is a pytorch tensor convert it into numpy array
    seg = np.array(seg)
    #color_seg is a variable to store mask which we convert to colorful visualization using our coloe palette
    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8) # height, width, 3\
    
    for label, color in enumerate(palette):

        color_seg[seg == label, :] = color
    # Convert to BGR
    color_seg = color_seg[..., ::-1]

    #calculate iou 
    iou_score = pd.concat([iou_score, calculate_iou(seg, mask, 5)], ignore_index=True)

    #calculate dice_coeff
    dice_coeff = pd.concat([dice_coeff, dice_coefficient(seg, mask, 5)], ignore_index=True)

    #find pixel_wise accuracy
    pixel_accuracy.append(pixel_wise_accuracy(seg, mask))
    


    #visuallize our prediction and orignal masks
    fig, axs = plt.subplots(1, 3, figsize=(20, 10))
    axs[0].imshow(image)  #orignal image
    axs[1].imshow(mask)   #orignal mask
    axs[2].imshow(color_seg) #predicted mask
    plt.show()







